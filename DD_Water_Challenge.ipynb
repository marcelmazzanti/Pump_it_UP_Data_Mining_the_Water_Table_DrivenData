{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:11:55.352720Z",
     "start_time": "2021-05-06T16:11:54.239603Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Importing Libraries ###\n",
    "import pandas as pd                                    # data science essentials\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                        # data visualization\n",
    "import seaborn as sns                                  # enhanced data visualization\n",
    "import statsmodels.formula.api as smf   \n",
    "import statsmodels.api as sm                           # regression (statsmodels)\n",
    "from sklearn.model_selection import train_test_split   # train/test split\n",
    "import sklearn.linear_model                            # different linear models\n",
    "import random as rand                                  # random number generation\n",
    "from sklearn.preprocessing import StandardScaler       # standard scaler\n",
    "from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "from sklearn.metrics import roc_auc_score              # auc score\n",
    "from sklearn.metrics import confusion_matrix           # confusion matrix\n",
    "from sklearn.metrics import make_scorer                # customizable scorer\n",
    "from sklearn.tree import DecisionTreeClassifier        # classification trees\n",
    "from sklearn.tree import export_graphviz               # exports graphics\n",
    "from sklearn.ensemble import GradientBoostingClassifier# gbm\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:11:59.255276Z",
     "start_time": "2021-05-06T16:11:55.353901Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "### Set up pandas settings and data loading ###\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "# Setting Data Types for the files\n",
    "# Train and Test\n",
    "dtypes_01 = {'id'            : str,\n",
    "             'region_code'   : str,\n",
    "             'district_code' : str}\n",
    "# Expected Output\n",
    "dtypes_02 = {'id' : str}\n",
    "\n",
    "# Import CSV Files\n",
    "raw_train_data_path = 'https://raw.githubusercontent.com/RLanderosR/Pump_it_UP_Data_Mining_the_Water_Table_DrivenData/main/Train_Data.csv'\n",
    "raw_train_outp_path = 'https://raw.githubusercontent.com/RLanderosR/Pump_it_UP_Data_Mining_the_Water_Table_DrivenData/main/Train_Outcome.csv'\n",
    "raw_test_data_path  = 'https://raw.githubusercontent.com/RLanderosR/Pump_it_UP_Data_Mining_the_Water_Table_DrivenData/main/Test_Data.csv'\n",
    "\n",
    "t_data   = pd.read_csv(raw_train_data_path,\n",
    "                       dtype = dtypes_01)\n",
    "\n",
    "out_data = pd.read_csv(raw_train_outp_path,\n",
    "                       dtype = dtypes_02)\n",
    "\n",
    "test     = pd.read_csv(raw_test_data_path,\n",
    "                       dtype = dtypes_01)\n",
    "\n",
    "# Merging the Test data with the expected Outcome\n",
    "train = pd.merge(t_data,out_data,on='id')\n",
    "\n",
    "# Setting the Column 'date_recorded' as datetime\n",
    "train['date_recorded'] = pd.to_datetime(train['date_recorded'])\n",
    "test['date_recorded']  = pd.to_datetime(test['date_recorded'])\n",
    "\n",
    "# Save id for test dataset\n",
    "test_id = test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:12:05.615893Z",
     "start_time": "2021-05-06T16:11:59.258157Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train['predict'] = 0\n",
    "\n",
    "for index, value in train.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if train.loc[index, 'status_group'] == 'non functional':\n",
    "        train.loc[index, 'predict'] = 1 \n",
    "\n",
    "# preparing explanatory variable data\n",
    "train_base_data   = train.drop(['id', 'amount_tsh', 'date_recorded', 'funder', \n",
    "                           'gps_height', 'installer', 'wpt_name', \n",
    "                           'num_private', 'basin', 'subvillage', 'region', \n",
    "                           'region_code', 'district_code', 'lga', 'ward', \n",
    "                           'recorded_by', 'scheme_management', 'scheme_name', \n",
    "                           'permit', 'construction_year'],\n",
    "                           axis = 1)\n",
    "\n",
    "# preparing explanatory variable data\n",
    "train_data   = train_base_data.drop(['status_group', 'predict'],\n",
    "                           axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:12:05.618403Z",
     "start_time": "2021-05-06T16:12:05.616874Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional vs Non Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:12:05.734802Z",
     "start_time": "2021-05-06T16:12:05.619331Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "NF_data = pd.get_dummies(train_data, prefix = 'd_')\n",
    "\n",
    "NF_data = NF_data.drop( columns = 'd__other - mkulima/shinyanga', axis = 1)\n",
    "\n",
    "# preparing response variables\n",
    "NF_target = train.loc[ : , 'predict']\n",
    "\n",
    "# preparing training and testing sets (all letters are lowercase)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            NF_data,\n",
    "            NF_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 42)\n",
    "\n",
    "# # checking the shapes of the datasets\n",
    "# print(f\"\"\"\n",
    "# Training Data\n",
    "# -------------\n",
    "# X-side: {x_train.shape}\n",
    "# y-side: {y_train.shape}\n",
    "\n",
    "\n",
    "# Testing Data\n",
    "# ------------\n",
    "# X-side: {x_test.shape}\n",
    "# y-side: {y_test.shape}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:17:35.956227Z",
     "start_time": "2021-05-06T16:12:05.736098Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "learn_space      = np.arange(0.1, 1.3, 0.1)\n",
    "estimator_space  = np.arange(20, 100, 10)\n",
    "depth_space      = np.arange(5, 9 , 1)\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'learning_rate'    : learn_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'n_estimators'     : estimator_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "NF_full_gbm_grid = GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "NF_full_gbm_cv = RandomizedSearchCV(estimator  = NF_full_gbm_grid,\n",
    "                           param_distributions = param_grid,\n",
    "                           cv                  = 3,\n",
    "                           n_iter              = 10,\n",
    "                           scoring             = make_scorer(roc_auc_score,\n",
    "                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "NF_full_gbm_cv.fit(NF_data, NF_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", NF_full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", NF_full_gbm_cv.best_score_.round(4))\n",
    "\n",
    "# checking the best estimator for the model\n",
    "NF_full_gbm_cv.best_estimator_\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "NF_gbm_tuned = NF_full_gbm_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "NF_gbm_tuned_pred = NF_gbm_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "NF_gbm_tuned_train_acc = NF_gbm_tuned.score(x_train, y_train).round(4)\n",
    "NF_gbm_tuned_test_acc  = NF_gbm_tuned.score(x_test, y_test).round(4)\n",
    "NF_gbm_tuned_auc  = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = NF_gbm_tuned_pred).round(4)\n",
    "NF_gbm_tuned_test_gap = abs(NF_gbm_tuned_train_acc-NF_gbm_tuned_test_acc).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', NF_gbm_tuned_train_acc)\n",
    "print('Testing  ACCURACY:', NF_gbm_tuned_test_acc)\n",
    "print('Train-Test Gap   :', NF_gbm_tuned_test_gap)\n",
    "print('AUC Score        :', NF_gbm_tuned_auc)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "NF_gbm_tuned_tn, \\\n",
    "NF_gbm_tuned_fp, \\\n",
    "NF_gbm_tuned_fn, \\\n",
    "NF_gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = NF_gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {NF_gbm_tuned_tn}\n",
    "False Positives: {NF_gbm_tuned_fp}\n",
    "False Negatives: {NF_gbm_tuned_fn}\n",
    "True Positives : {NF_gbm_tuned_tp}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional vs Needs Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:17:39.175266Z",
     "start_time": "2021-05-06T16:17:35.958472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train_base_data['predict'] = 0\n",
    "\n",
    "for index, value in train_base_data.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if train_base_data.loc[index, 'status_group'] == 'functional needs repair':\n",
    "        train_base_data.loc[index, 'predict'] = 1 \n",
    "\n",
    "# preparing explanatory variable data\n",
    "FNR_data   = train_base_data.drop(['status_group', 'predict'],\n",
    "                           axis = 1)\n",
    "\n",
    "FNR_data = pd.get_dummies(FNR_data, prefix = 'd_')\n",
    "\n",
    "FNR_data = FNR_data.drop( columns = 'd__other - mkulima/shinyanga', axis = 1)\n",
    "\n",
    "# preparing response variables\n",
    "FNR_target = train_base_data.loc[ : , 'predict']\n",
    "\n",
    "# preparing training and testing sets (all letters are lowercase)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            FNR_data,\n",
    "            FNR_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:23:18.992577Z",
     "start_time": "2021-05-06T16:17:39.176888Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "learn_space      = np.arange(0.1, 1.3, 0.1)\n",
    "estimator_space  = np.arange(20, 100, 10)\n",
    "depth_space      = np.arange(5, 9 , 1)\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'learning_rate'    : learn_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'n_estimators'     : estimator_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "FNR_full_gbm_grid = GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "FNR_full_gbm_cv = RandomizedSearchCV(estimator = FNR_full_gbm_grid,\n",
    "                           param_distributions = param_grid,\n",
    "                           cv                  = 3,\n",
    "                           n_iter              = 10,\n",
    "                           scoring             = make_scorer(roc_auc_score,\n",
    "                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "FNR_full_gbm_cv.fit(FNR_data, FNR_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", FNR_full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", FNR_full_gbm_cv.best_score_.round(4))\n",
    "\n",
    "# checking the best estimator for the model\n",
    "FNR_full_gbm_cv.best_estimator_\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "FNR_gbm_tuned = FNR_full_gbm_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "FNR_gbm_tuned_pred = FNR_gbm_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "FNR_gbm_tuned_train_acc = FNR_gbm_tuned.score(x_train, y_train).round(4)\n",
    "FNR_gbm_tuned_test_acc  = FNR_gbm_tuned.score(x_test, y_test).round(4)\n",
    "FNR_gbm_tuned_auc  = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = FNR_gbm_tuned_pred).round(4)\n",
    "FNR_gbm_tuned_test_gap = abs(FNR_gbm_tuned_train_acc-FNR_gbm_tuned_test_acc).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', FNR_gbm_tuned_train_acc)\n",
    "print('Testing  ACCURACY:', FNR_gbm_tuned_test_acc)\n",
    "print('Train-Test Gap   :', FNR_gbm_tuned_test_gap)\n",
    "print('AUC Score        :', FNR_gbm_tuned_auc)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "FNR_gbm_tuned_tn, \\\n",
    "FNR_gbm_tuned_fp, \\\n",
    "FNR_gbm_tuned_fn, \\\n",
    "FNR_gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = FNR_gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {FNR_gbm_tuned_tn}\n",
    "False Positives: {FNR_gbm_tuned_fp}\n",
    "False Negatives: {FNR_gbm_tuned_fn}\n",
    "True Positives : {FNR_gbm_tuned_tp}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:23:27.075592Z",
     "start_time": "2021-05-06T16:23:18.993538Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "train_base_data['predict'] = 0\n",
    "\n",
    "for index, value in train_base_data.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if train_base_data.loc[index, 'status_group'] == 'functional':\n",
    "        train_base_data.loc[index, 'predict'] = 1 \n",
    "\n",
    "# preparing explanatory variable data\n",
    "F_data   = train_base_data.drop(['status_group', 'predict'],\n",
    "                           axis = 1)\n",
    "\n",
    "F_data = pd.get_dummies(F_data, prefix = 'd_')\n",
    "\n",
    "F_data = F_data.drop( columns = 'd__other - mkulima/shinyanga', axis = 1)\n",
    "\n",
    "# preparing response variables\n",
    "F_target = train_base_data.loc[ : , 'predict']\n",
    "\n",
    "# preparing training and testing sets (all letters are lowercase)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            F_data,\n",
    "            F_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:29:01.993817Z",
     "start_time": "2021-05-06T16:23:27.076707Z"
    }
   },
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "learn_space      = np.arange(0.1, 1.3, 0.1)\n",
    "estimator_space  = np.arange(20, 100, 10)\n",
    "depth_space      = np.arange(5, 9 , 1)\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'learning_rate'    : learn_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'n_estimators'     : estimator_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "F_full_gbm_grid = GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "F_full_gbm_cv = RandomizedSearchCV(estimator = F_full_gbm_grid,\n",
    "                           param_distributions = param_grid,\n",
    "                           cv                  = 3,\n",
    "                           n_iter              = 10,\n",
    "                           scoring             = make_scorer(roc_auc_score,\n",
    "                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "F_full_gbm_cv.fit(F_data, F_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", F_full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", F_full_gbm_cv.best_score_.round(4))\n",
    "\n",
    "# checking the best estimator for the model\n",
    "F_full_gbm_cv.best_estimator_\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "F_gbm_tuned = F_full_gbm_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "F_gbm_tuned_pred = F_gbm_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "F_gbm_tuned_train_acc = F_gbm_tuned.score(x_train, y_train).round(4)\n",
    "F_gbm_tuned_test_acc  = F_gbm_tuned.score(x_test, y_test).round(4)\n",
    "F_gbm_tuned_auc  = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = F_gbm_tuned_pred).round(4)\n",
    "F_gbm_tuned_test_gap = abs(F_gbm_tuned_train_acc-F_gbm_tuned_test_acc).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', F_gbm_tuned_train_acc)\n",
    "print('Testing  ACCURACY:', F_gbm_tuned_test_acc)\n",
    "print('Train-Test Gap   :', F_gbm_tuned_test_gap)\n",
    "print('AUC Score        :', F_gbm_tuned_auc)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "F_gbm_tuned_tn, \\\n",
    "F_gbm_tuned_fp, \\\n",
    "F_gbm_tuned_fn, \\\n",
    "F_gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = F_gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {F_gbm_tuned_tn}\n",
    "False Positives: {F_gbm_tuned_fp}\n",
    "False Negatives: {F_gbm_tuned_fn}\n",
    "True Positives : {F_gbm_tuned_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:29:02.014197Z",
     "start_time": "2021-05-06T16:29:01.994761Z"
    }
   },
   "outputs": [],
   "source": [
    "NF_predictions = pd.DataFrame({'Non Funtional' : NF_gbm_tuned_pred})\n",
    "\n",
    "FNR_predictions = pd.DataFrame({'Funtional Needs Repair' : FNR_gbm_tuned_pred})\n",
    "\n",
    "F_predictions = pd.DataFrame({'Funtional' : F_gbm_tuned_pred})\n",
    "\n",
    "all_predictions = pd.concat([train['id'],\n",
    "                             train['status_group'],\n",
    "                             NF_predictions,\n",
    "                             FNR_predictions,\n",
    "                             F_predictions],\n",
    "                               axis = 1)\n",
    "\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:30:26.503797Z",
     "start_time": "2021-05-06T16:30:26.352480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the data to be forcasted\n",
    "df_test   = test.drop(['id', 'amount_tsh', 'date_recorded', 'funder', \n",
    "                           'gps_height', 'installer', 'wpt_name', \n",
    "                           'num_private', 'basin', 'subvillage', 'region', \n",
    "                           'region_code', 'district_code', 'lga', 'ward', \n",
    "                           'recorded_by', 'scheme_management', 'scheme_name', \n",
    "                           'permit', 'construction_year'],\n",
    "                           axis = 1)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, prefix = 'd_')\n",
    "\n",
    "NF_pred  = NF_gbm_tuned.predict(df_test)\n",
    "\n",
    "FNR_pred = FNR_gbm_tuned.predict(df_test)\n",
    "\n",
    "F_pred   = F_gbm_tuned.predict(df_test)\n",
    "\n",
    "data = {'id' : test_id,\n",
    "        'NF_pred'  : NF_pred,\n",
    "        'FNR_pred' : FNR_pred,\n",
    "        'F_pred'   : F_pred,\n",
    "       }\n",
    "\n",
    "df_response = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:39:13.546794Z",
     "start_time": "2021-05-06T16:39:10.681157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating flags to enable data exploration\n",
    "df_response['all_true'] = 0 \n",
    "\n",
    "for index, value in df_response.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if  df_response.loc[index, 'NF_pred'] == 1 & \\\n",
    "        df_response.loc[index, 'FNR_pred'] == 1 & \\\n",
    "        df_response.loc[index, 'F_pred'] == 1:\n",
    "        df_response.loc[index, 'all_true'] = 1\n",
    "        \n",
    "df_response['NF_FNR'] = 0 \n",
    "\n",
    "for index, value in df_response.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if  df_response.loc[index, 'NF_pred'] == 1 & \\\n",
    "        df_response.loc[index, 'FNR_pred'] == 1:\n",
    "        df_response.loc[index, 'NF_FNR'] = 1\n",
    "        \n",
    "df_response['NF_F'] = 0 \n",
    "\n",
    "for index, value in df_response.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if  df_response.loc[index, 'NF_pred'] == 1 & \\\n",
    "        df_response.loc[index, 'F_pred'] == 1:\n",
    "        df_response.loc[index, 'NF_F'] = 1\n",
    "        \n",
    "df_response['FNR_F'] = 0 \n",
    "\n",
    "for index, value in df_response.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if  df_response.loc[index, 'FNR_pred'] == 1 & \\\n",
    "        df_response.loc[index, 'F_pred'] == 1:\n",
    "        df_response.loc[index, 'FNR_F'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:49:09.942418Z",
     "start_time": "2021-05-06T16:49:06.319110Z"
    }
   },
   "outputs": [],
   "source": [
    "## 0.7902 Score Submission\n",
    "\n",
    "# Creating a copy to explore the data\n",
    "explore = df_response.copy()\n",
    "\n",
    "# Creating column to translate the binaries into the actual statuses\n",
    "\n",
    "explore['status_group'] = 'functional'\n",
    "\n",
    "for index, value in explore.iterrows():    \n",
    "\n",
    "    # loop to get the unique choice\n",
    "    if   explore.loc[index, 'NF_pred'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'non functional'\n",
    "        \n",
    "    elif explore.loc[index, 'FNR_pred'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'functional needs repair'\n",
    "        \n",
    "        \n",
    "# Managing the values that overlap with the other GBM\n",
    "for index, value in explore.iterrows():    \n",
    "\n",
    "    # All True then Pump is FUNCTIONAL\n",
    "    if   explore.loc[index, 'all_true'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'functional'\n",
    "        \n",
    "    # Non Functional and Funcitonal Needs Repair is Funcitonal Needs Repair\n",
    "    elif explore.loc[index, 'NF_FNR'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'functional needs repair'\n",
    "        \n",
    "    # Non Functional and Funcitonal is NON Funcitonal\n",
    "    elif explore.loc[index, 'NF_F'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'non functional'\n",
    "        \n",
    "    # Funcitonal Needs Repair Functional and Funcitonal\n",
    "    elif explore.loc[index, 'FNR_F'] == 1:\n",
    "        explore.loc[index, 'status_group'] = 'functional'\n",
    "\n",
    "        \n",
    "sumbission_test = explore.copy()\n",
    "\n",
    "sumbission_test = sumbission_test.drop(columns = ['NF_pred', 'FNR_pred', \n",
    "                                                  'F_pred', 'all_true', \n",
    "                                                  'NF_FNR', 'NF_F', 'FNR_F'],\n",
    "                             axis = 1)\n",
    "\n",
    "sumbission_test.to_csv('pump_it_RLR_logic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:31:42.656640Z",
     "start_time": "2021-05-06T16:31:40.176536Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating a column to translate the binaries into the actual statuses\n",
    "# df_response['status_group'] = 'functional'\n",
    "\n",
    "# for index, value in df_response.iterrows():    \n",
    "\n",
    "#     # loop to get the unique choice\n",
    "#     if   df_response.loc[index, 'NF_pred'] == 1:\n",
    "#         df_response.loc[index, 'status_group'] = 'non functional'\n",
    "        \n",
    "#     elif df_response.loc[index, 'FNR_pred'] == 1:\n",
    "#         df_response.loc[index, 'status_group'] = 'functional needs repair'\n",
    "        \n",
    "# sumbission = df_response.copy()\n",
    "\n",
    "# sumbission = sumbission.drop(columns = ['NF_pred', 'FNR_pred', 'F_pred'],\n",
    "#                              axis = 1)\n",
    "\n",
    "# sumbission.to_csv('pump_it_RLR.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
